%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[10pt, a4paper, twocolumn]{article} % 10pt font size (11 and 12 also possible), A4 paper (letterpaper for US letter) and two column layout (remove for one column)

\input{structure.tex} % Specifies the document structure and loads requires packages

%----------------------------------------------------------------------------------------
%	ARTICLE INFORMATION
%----------------------------------------------------------------------------------------

\title{Effective Methods for Capturing Cattle Rustlers} % The article title

\author{
	\authorstyle{John Marston\textsuperscript{1,2,3} and Bonnie MacFarlane\textsuperscript{2,3}} % Authors
	\newline\newline % Space before institutions
	\textsuperscript{1}\institution{Università degli studi di Padova, Padova, Italy}\\ % Institution 1
}

% Example of a one line author/institution relationship
%\author{\newauthor{John Marston} \newinstitution{Universidad Nacional Autónoma de México, Mexico City, Mexico}}

\date{\today} % Add a date here if you would like one to appear underneath the title block, use \today for the current date, leave empty for no date

%----------------------------------------------------------------------------------------

\begin{document}

\maketitle % Print the title

\thispagestyle{firstpage} % Apply the page style for the first page (no headers and footers)

%----------------------------------------------------------------------------------------
%	ABSTRACT
%----------------------------------------------------------------------------------------

\lettrineabstract{WIP}
%----------------------------------------------------------------------------------------
%	ARTICLE CONTENTS
%----------------------------------------------------------------------------------------

\section{Introduction}

IOT (Internet of Things) devices are usually tiny and connected to a large network of alike where they exchange sensible data.
These devices usually have low computational capabilities and exchange sensible data to each other.
It seems reasonable now that we want a computationally efficient and secure way of attestating the integrity of the network.
Remote Attestation allows to interrogate a network and ask for its status in a decentralized way and can be performed by each node of the network.
Collective Remote Attestation adds on top of this the possibility of checking the status of the whole network in a single operation, possibly fast to compute.
SANA (Secure and Scalable Aggregated Network Attestation) wants to provide an attestation protocol for large IOT deployments.
It does so by utilizing a signature scheme called OAS (Optimistic Aggregated Signature) which allows the aggregation of signatures of different devices, making the verification of this aggregated singature constant to the number of compromised devices in the network, instead of constant with the number of all the devices.
In this article we want to focus on the claims SANA made when it was presented, in particular about its security and its weight among the devices.
SANA comes with some estimations about its memory, communication, and computational costs. But the formulas neglect specifying some variables that prove to be decisive to determine these estimations.
We chose to implement the protocol using an ECC algorithm based on Ethereum to handle the signing and verification phases of the protocol, then we analyzed the results to prove the claims that were given in the SANA paper and at last make some considerations about the criticality of this protocol.
%------------------------------------------------


%------------------------------------------------
 
\section{Premises}

\begin{figure}
	\includegraphics[width=\linewidth]{images/SANA_general.png} % Figure image
	\caption{SANA propagation tree} % Figure caption
	\label{bear} % Label for referencing with \ref{bear}
\end{figure}

Elliptic Curve Cryptography is based, like all Public-key cryptography, on the intractability of some mathematical problems.
For elliptic curve based protocol in particular it's based on the ability to compute easily a point multiplication and the inability to compute the scalar multiplicand given the original point and the result.
All this operations are performed with respect to the finite field the curve is associated with.
In this protocol we use ECC to generate public keys that belong to a multiplicative group that is composed by points on the curve we have chosen for the cryptrographic system.
After that all the signatures are generated by a random oracle as points belonging to the curve. We then use a fancy property of Elliptic curve to perform a bilinear function (called also pairing) on the signature received and a reconstruction of what should be the signature to check if it's authentic in a computationally efficient way.
In SANA the remote attestation process starts from the verifier that sends a request to the Owner that generates a Token and propagates it to the Verifier (containing a challenge that will be proposed to the other nodes in order to certify the authenticity of the attestation request). The Verifier checks the signature and, if it has a positive result, stores the token. \\The Verifier then
the challenge to the closest Aggregator in the propagation tree, this node proceeds to propagate the challenge to its neighbours being other Aggregator
or Provers. The latter then sign a message according to their software configuration being legit or compromised. The signature travel back to the Aggregator
that creates the aggregated signature of its neighbours. Lastly the Verifier checks the aggregated signature of all the tree and determines which devices
can be trusted and which are compromised.\\
For implementing this protocol we chose an elliptic-curve implementation used in Ethereum and called ''bn128'' as it uses a Barreto-Naehrig curve and it's said to offer 128 bits security.


\section{Implementation and analysis}

We wrote an implementation of the algorithm in python, we first defined all the different classes in order to simulate all the nodes (Prover, Aggregator, Owner and Verifier) where neighbours can be assigned to each node in order to resemble a static network configuration.
Before utilizing ''bn128'' we tried to define our curve for the ECC cryptography implementation but for the vast majority of curves that you can choose don't have an easily computable bilinear map, so they were not suitable for our work. At last we decided to use an already existing curve called Barreto-Naherig curve.
After choosing the curve we incorporated the ''bn128'' implementation in our code adding various helping function to generate the keys, software configurations, tokens and challenges.
This implementation uses the Barreto-Naehrig curve on a finite field Zp with p of 256 bits, for the computation of the bilinear map this implementation relies on the Tate-pairing technique which is the fastest for this task. In fact, compared to the Weil pairing the Tate pairing requires only one iteration of the Miller's loop function instead of three simplyfying a lot the computation of the pairing.

We now proceed to evaluate the computational, memory and communication costs of SANA for Provers and Aggregators since we can't make assumption on their costs and the algorithm needs to be feasible even for low-end devices.
Starting from the computational cost we can see that the most complex functions of the protocol are the sign and verify functions as they both have to perform operations on the elliptic curve that require several multiplication to be executed.
\begin{table}
	\caption{Computational cost for each function}
	\centering
	\begin{tabular}{llr}
		\toprule
		Function & Node & Cost \\
		\midrule
		Sign & Prover & $O(n^2log(n))$ \\
		Aggregate & Aggregator & $O(n log(n))$ \\
		Verify & Verifier & $O(n^2log(n))$ \\
		\bottomrule
	\end{tabular}
\end{table}
So we can safely say that the highest cost falls on the provers while the aggregators, which only have to perform one multiplication between objects.

\section{Methods and tools}

For what concerns the work shown above, we wrote our implementation in python and ran it on a google colab instance with multi-threading enabled in order to resemble the possible interaction with the network.
We then executed experiments with different number of provers, different compromised devices rate in order to extract execution time for the most important step of the algorithm.
After that we proceded by performing theorical considerations and calculations in order to estimate the computational complexity, the memory and communication cost, and the total time of the algorithm.

\section{Results}
\subsection{Time cost of Aggregation}
For what concerns the duration of the process of aggregation we extracted the aggregation time of 1 aggregator with an increasing number of provers connected to him to see if our theoretical guesses are correct.
\begin{figure}
	\includegraphics[width=\linewidth]{images/aggregation_0.png} % Figure image
	\caption{Aggregation time with 0\% bad provers up to 1000 provers} % Figure caption
	\label{bear} % Label for referencing with \ref{bear}
\end{figure}

Firstly we can see in figure 2 the aggregation time of up to 1000 provers with 0\% of them being bad provers, this means that all of them signed the default message, theoretically we supposed that the cost in time 
for the process of aggregation wuold increase linearly with the number of provers connected to the same aggregator. We can clearly see that our supposition were correct.
Now the question was if aggregation time depends on the number of bad provers within all the provers connected to the aggregator.\\

\begin{figure}
	\includegraphics[width=\linewidth]{images/aggregation_100.png} % Figure image
	\caption{Aggregation time with 100\% bad provers up to 1000 provers} % Figure caption
	\label{bear} % Label for referencing with \ref{bear}
\end{figure}

As we supposed the percentage of bad provers do not influence the time of aggregation, in fact with 100\% bad provers (figure 3) the graph is very close to the 0\% one.\\ 
We extracted data for 0\% 25\% 50\% 75\% and 100\% of bad provers, the results in figure 4.\\
\begin{figure}
	\includegraphics[width=\linewidth]{images/aggregation_comparison.png} % Figure image
	\caption{Aggregation time with all percentage of bad provers up to 1000 provers} % Figure caption
	\label{bear} % Label for referencing with \ref{bear}
\end{figure}

\subsection{Time cost of Verification}
The other parameter we wanted to investigate was the verification time of the aggregator with respect to the number of provers and the percentage of them not signing the default message.
Theoretically we believed that the number of bad provers would make the verification time increase linearly, and on the other hand the time of verification should be independent on the number of legitimate provers.\\

\begin{figure}
	\includegraphics[width=\linewidth]{images/Verification_0.png} % Figure image
	\caption{Verification time cost with 0 bad provers} % Figure caption
	\label{bear} % Label for referencing with \ref{bear}
\end{figure}
In Figure 5 we can see that the time of verification is in fact independent from the number of provers if they are all legitimate.\\
\begin{figure}
	\includegraphics[width=\linewidth]{images/verification_100.png} % Figure image
	\caption{Verfication cost with all the provers being bad provers} % Figure caption
	\label{bear} % Label for referencing with \ref{bear}
\end{figure}
Intsead, with 100\% of bad provers in Figure 6, the time of verification increase linearly with the number of provers, reaching up to 6000 seconds for the verification of 1000 bad provers.\\
\begin{figure}
	\includegraphics[width=\linewidth]{images/verification_comparison.png} % Figure image
	\caption{Verification time costs comparison with different percentage of bad provers} % Figure caption
	\label{bear} % Label for referencing with \ref{bear}
\end{figure}
The comparison of the verification time of 0\% 25\% 50\% 75\% 100\% bad provers is represented in Figure 7.\\

\subsection{Memory cost}
\begin{figure}
	\includegraphics[width=\linewidth]{images/memorycost.png} % Figure image
	\caption{Memory cost for the aggregator } % Figure caption
	\label{bear} % Label for referencing with \ref{bear}
\end{figure}
In Figure 8 is represented the memory cost for the aggregator, theoretically we expected this to increase linearly with the number of bad neighbours due to the nature of the protocol identifying the compromised devices. In fact we proved this claim to be true and we can add to that the aggregator must suffer a memory cost that for the majority of low end devices is prohibiting having close to 1024Kb of memory.\\
\section{Conclusions}

In hac habitasse platea dictumst. Vivamus eu finibus leo. Donec malesuada dui non sagittis auctor. Aenean condimentum eros metus. Nunc tempus id velit ut tempus. Quisque fermentum, nisl sit amet consectetur ornare, nunc leo luctus leo, vitae mattis odio augue id libero. Mauris quis lectus at ante scelerisque sollicitudin in eu nisi. Nulla elit lacus, ultricies eu erat congue, venenatis semper turpis. Ut nec venenatis velit. Mauris lacinia diam diam, ac egestas neque sodales sed. Curabitur eu diam nulla. Duis nec turpis finibus, commodo diam sed, bibendum erat. Nunc in velit ullamcorper, posuere libero a, mollis mauris. Nulla vehicula quam id tortor ornare blandit. Aenean maximus tempor orci ultrices placerat. Aenean condimentum magna vulputate erat mattis feugiat.

%----------------------------------------------------------------------------------------
%	BIBLIOGRAPHY
%----------------------------------------------------------------------------------------

\printbibliography[title={Bibliography}] % Print the bibliography, section title in curly brackets

%----------------------------------------------------------------------------------------

\end{document}
